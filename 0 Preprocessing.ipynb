{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b325419-4932-4b41-8c86-201d06ce5c16",
   "metadata": {},
   "source": [
    "# 1 Read in Labels.csv turn it into labels.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed7145b-7ef3-4f35-a3fc-03d9e24ae21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Read in the CSV file and turn it into a Python list\n",
    "csv_file_path = 'Data/Metaphors/labels.csv'  # Replace with the actual file path\n",
    "python_list = []\n",
    "\n",
    "with open(csv_file_path, mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        # Assuming each row contains one element which is the label\n",
    "        python_list.append(int(row[0]))\n",
    "\n",
    "# Save the Python list to a JSON file\n",
    "json_file_path = 'Data/Metaphors/labels.json'  # Replace with the desired output file path\n",
    "\n",
    "with open(json_file_path, mode='w') as file:\n",
    "    json.dump(python_list, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497183a-81f2-4862-a795-7ceda114c258",
   "metadata": {},
   "source": [
    "## 1.1 Metaphors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef56f575-3ed0-4277-9e31-2b844457080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Data/Metaphors/metaphors.csv'\n",
    "def read_csv_in_batches(file_path, batch_size=40):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        batch = []\n",
    "        i=1\n",
    "        for row in reader:\n",
    "            batch.append(str(i)+'.'+row[0])  # Assuming each row has one sentence\n",
    "            i+=1\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                i=1\n",
    "        if batch:\n",
    "            yield batch\n",
    "raw=[]\n",
    "for batch in read_csv_in_batches(file_path, 10):\n",
    "    sen = \"\\n\".join(batch)+\"\\n\"\n",
    "    raw.append(sen)\n",
    "print(len(raw))\n",
    "\n",
    "json_file_path = 'Data/Metaphors/raw.json'  # Replace with the desired output file path\n",
    "\n",
    "with open(json_file_path, mode='w') as file:\n",
    "    json.dump(raw, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad81258-2697-4bfc-9f8c-2fdfbc055815",
   "metadata": {},
   "source": [
    "## 1.2 Hyperboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2e9709f-130f-4ea9-8e4e-688059e5e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "file_path = 'Data/Hyperboles/hypo/test.csv'\n",
    "def read_csv_in_batches(file_path, batch_size=40):\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        batch = []\n",
    "        i=1\n",
    "        for row in reader:\n",
    "            batch.append(str(i)+'.'+row[0])  # Assuming each row has one sentence\n",
    "            i+=1\n",
    "            if len(batch) == batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "                i=1\n",
    "        if batch:\n",
    "            yield batch\n",
    "raw=[]\n",
    "for batch in read_csv_in_batches(file_path, 10):\n",
    "    sen = \"\\n\".join(batch)+\"\\n\"\n",
    "    raw.append(sen)\n",
    "print(len(raw))\n",
    "\n",
    "json_file_path = 'Data/Hyperboles/raw.json'  # Replace with the desired output file path\n",
    "\n",
    "with open(json_file_path, mode='w') as file:\n",
    "    json.dump(raw, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e70560-88da-4620-9b1e-005d5291601f",
   "metadata": {},
   "source": [
    "# 2 Process [the SemEval-2017 Task 7](https://alt.qcri.org/semeval2017/task7/index.php?id=data-and-resources) homographic pun detection\n",
    "In this part turn the original XML data format to sentence list format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb7290f1-1971-4fec-9070-b16a828f995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'Data/HomographicPuns/data/test.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0685d15-d066-44e8-8f88-910349e1d21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def xml_to_sentences(file_path):\n",
    "    # Load the XML file\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # List to store sentences\n",
    "    sentences = []\n",
    "\n",
    "    # Iterate through 'text' elements\n",
    "    for text in root.findall('text'):\n",
    "        # List to store words in the current sentence\n",
    "        sentence_words = []\n",
    "\n",
    "        # Iterate through 'word' elements within each 'text' element\n",
    "        for word in text.findall('word'):\n",
    "            # Append the text of each 'word' element to the sentence_words list\n",
    "            sentence_words.append(word.text)\n",
    "\n",
    "        # Join the words to form a sentence and add it to the sentences list\n",
    "        sentences.append(' '.join(sentence_words))\n",
    "\n",
    "    return sentences\n",
    "\n",
    "# Specify the path to your XML file\n",
    "# file_path = 'path_to_your_file.xml'\n",
    "\n",
    "# Get the list of sentences\n",
    "sentences = xml_to_sentences(file)\n",
    "\n",
    "# Print the sentences\n",
    "# for sentence in sentences:\n",
    "#     print(sentence)\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e84b08a-51b6-4b1f-a285-5265d58f0fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "1.They hid from the gunman in a sauna where they could sweat it out .\n",
      "2.Wal - Mart isn ' t the only saving place !\n",
      "3.Can honeybee abuse lead to a sting operation ?\n",
      "4.A ditch digger was entrenched in his career .\n",
      "5.She was only a Blacksmith ' s daughter , but she knew how to forge ahead .\n",
      "6.86 of Borg : You will be assimilated . Would you believe , stood close to ?\n",
      "7.Did you hear about the new pinata ? It ' s a huge hit .\n",
      "8.A bank manager who was also a high jumper spent most of his time in the vault .\n",
      "9.A discussion of digging a new mine shaft was too deep for him .\n",
      "10.She was suspected of stealing a brooch but they couldn ' t pin it on her .\n"
     ]
    }
   ],
   "source": [
    "raw=[]\n",
    "# original_list = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# original_list = ['a', 'b', 'c', 'd', ...]  # Add more elements as needed\n",
    "\n",
    "def format_list(lst, group_size=10):\n",
    "    # New list to store the formatted strings\n",
    "    formatted_list = []\n",
    "\n",
    "    # Iterate over the list in steps of 'group_size'\n",
    "    for i in range(0, len(lst), group_size):\n",
    "        # Gather up to 'group_size' elements in the group\n",
    "        group_elements = [f'{idx + 1}.{lst[i + idx]}' for idx in range(min(group_size, len(lst) - i))]\n",
    "\n",
    "        # Join the group elements with a newline and add to the formatted list\n",
    "        formatted_list.append('\\n'.join(group_elements))\n",
    "\n",
    "    return formatted_list\n",
    "\n",
    "# Call the function and print the result\n",
    "raw = format_list(sentences)\n",
    "print(len(raw))\n",
    "print(raw[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96838df2-9c4e-4a72-aedb-9aaa52225a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.She was only a Watchman ' s daughter , but any time suited her .\n",
      "2.Weather forecasters have to have lots of degrees .\n",
      "3.\" And we had to chisel taglines into the walls of the cave . . . . \"\n",
      "4.OLD SANITATION MEN never die , they just waste away\n",
      "5.To become an electrician you have to pass a battery of tests .\n",
      "6.Choose a wife rather by your ear than your eye .\n",
      "7.Never test for an error you don ' t know how to handle .\n",
      "8.OLD MUSICIANS never die they just get played out .\n",
      "9.If you burn the candle on both ends , youâ€™re not as bright as you think .\n",
      "10.A student limped into class with a lame excuse .\n"
     ]
    }
   ],
   "source": [
    "print(raw[224])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0ff8cc3-ee02-4bfc-80f0-e274c3977e1d",
   "metadata": {},
   "source": [
    "def file_to_numerical_list(file_path):\n",
    "    # List to store the numerical values\n",
    "    numerical_list = []\n",
    "\n",
    "    # Open and read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line by tab character\n",
    "            parts = line.strip().split('\\t')\n",
    "            \n",
    "            # Check if the line has two parts\n",
    "            if len(parts) == 2:\n",
    "                # Append the numerical part (second part) to the list\n",
    "                numerical_list.append(int(parts[1]))\n",
    "\n",
    "    return numerical_list\n",
    "\n",
    "# Specify the path to your file\n",
    "file_path = 'Puns/data/test.gold'\n",
    "\n",
    "# Convert the file content to a numerical list\n",
    "numerical_list = file_to_numerical_list(file_path)\n",
    "\n",
    "# Print the list\n",
    "print(len(numerical_list))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "358b2c56-2005-4838-b4fd-797f92827607",
   "metadata": {},
   "source": [
    "# json_file_path = 'Puns/data/rawP.json'  \n",
    "with open('Puns/rawP.json' , mode='w') as file:\n",
    "    json.dump(raw, file)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d195d93-75fe-41df-ae0c-43c9879d4ec1",
   "metadata": {},
   "source": [
    "# json_file_path = 'Puns/data/rawP.json'\n",
    "import json\n",
    "with open('Puns/labelP.json' , mode='w') as file:\n",
    "    json.dump(numerical_list, file)\n",
    "print(len(numerical_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637cc75-8ce0-42f7-bde5-f35f1b4de3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
